name: CI testing

# see: https://help.github.com/en/actions/reference/events-that-trigger-workflows
on: # Trigger the workflow on push or pull request, but only for the main branch
  push: {}
  pull_request:
    branches: [main]

defaults:
  run:
    shell: bash

jobs:
  pytester:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-22.04", "macOS-13", "windows-2022"]
        python-version: ["3.9", "3.12"]
        requires: ["latest"]
        include:
          - { os: "ubuntu-20.04", python-version: "3.9", requires: "oldest" }

    # Timeout: https://stackoverflow.com/a/59076067/4521646
    timeout-minutes: 35
    env:
      TORCH_URL: "https://download.pytorch.org/whl/cpu/torch_stable.html"

    steps:
      - uses: actions/checkout@v4
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: "pip"

      - name: Set min. dependencies
        if: matrix.requires == 'oldest'
        run: |
          pip install 'lightning-utilities[cli]'
          python -m lightning_utilities.cli requirements set-oldest --req_files='["requirements.txt"]'

      - name: Install package & dependencies
        run: |
          pip --version
          pip install -e '.[test,extra]' -U -q --find-links $TORCH_URL
          pip list

      - name: Tests
        env: # the following values are just dummies since the actual http calls are mocked out
          LIGHTNING_USER_ID: ${{ secrets.LIGHTNING_USER_ID }}
          LIGHTNING_API_KEY: ${{ secrets.LIGHTNING_API_KEY }}
        run: |
          coverage run --source litmodels -m pytest src tests -v

      - name: Statistics
        run: |
          coverage report
          coverage xml

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          flags: unittests
          env_vars: OS,PYTHON
          name: codecov-umbrella
          fail_ci_if_error: false

  tests-guardian:
    runs-on: ubuntu-latest
    needs: pytester
    if: always()
    steps:
      - run: echo "${{ needs.pytester.result }}"
      - name: failing...
        if: needs.pytester.result == 'failure'
        run: exit 1
      - name: cancelled or skipped...
        if: contains(fromJSON('["cancelled", "skipped"]'), needs.pytester.result)
        timeout-minutes: 1
        run: sleep 90
